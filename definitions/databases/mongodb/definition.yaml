# definitions/databases/mongodb/definition.yaml
# Helm values for Bitnami MongoDB chart

# Apply common labels to all resources created by the chart
commonLabels:
  unbind/usd-type: {{ .Definition.Type | quote }}
  unbind/usd-version: {{ .Definition.Version | quote }}
  unbind/usd-category: databases
  {{- range $key, $value := .Parameters.labels }}
  {{ $key }}: {{ $value | quote }}
  {{- end }}

# Use ReplicaSet architecture
architecture: standalone

global:
  security:
    allowInsecureImages: true

# Image version - NOTE: Ensure this maps to a valid Bitnami tag format (e.g., "7.0", "7.0.5-debian-11-r0").
# The exact tag might need manual adjustment based on available Bitnami images for the desired MongoDB version.
image:
  repository: ghcr.io/unbindapp/bitnami-mongodb
  tag: {{ if eq (.Parameters.version | default "8.0") "8.0" }}8.0.9{{ else if eq .Parameters.version "7.0" }}7.0.20{{ else if eq .Parameters.version "6.0" }}6.0.23{{ else }} 8.0.9{{ end }}

extraFlags:
  - "--wiredTigerCacheSizeGB=0.25"
  - "--maxConns=100"            
  - "--wiredTigerCollectionBlockCompressor=zstd"

# Authentication - Requires a pre-existing secret
auth:
  enabled: true
  # Secret must contain keys 'mongodb-root-password' and 'mongodb-replica-set-key'
  existingSecret: {{ .Parameters.existingSecretName }}

# Persistence configuration
persistence:
  enabled: true
  size: {{ .Parameters.common.storage | default "1Gi" | quote }}

# Resource configuration
resourcesPreset: "none" # Use custom resources below
resources:
  requests:
    cpu: {{ .Parameters.common.resources.requests.cpu | default "100m" | quote }}
    memory: {{ .Parameters.common.resources.requests.memory | default "128Mi" | quote }}
  limits:
    cpu: {{ .Parameters.common.resources.limits.cpu | default "500m" | quote }}
    memory: {{ .Parameters.common.resources.limits.memory | default "256Mi" | quote }}

# Optional: Inject environment variables from parameters
{{- if .Parameters.environment }}
extraEnvVars:
{{- range $k, $v := .Parameters.environment }}
  - name: {{ $k | quote }}
    value: {{ $v | quote }}
{{- end }}
{{- end }}

# External Access via LoadBalancer (if requested)
{{- if .Parameters.common.exposeExternal }}
externalAccess:
  enabled: true
  service:
    type: LoadBalancer
    ports:
      mongodb: 27017
    # Optional: Configure loadBalancerSourceRanges, annotations etc. if needed via .Parameters
{{- else }}
# Ensure external access is explicitly disabled if not requested
externalAccess:
  enabled: false
{{- end }}

# Arbiter is enabled by default in the chart values, disable unless specifically needed/parameterized
arbiter:
  enabled: false

# Disable metrics exporter unless explicitly configured via parameters (not currently supported)
metrics:
  enabled: false

backup:
  enabled: false

{{- if .Parameters.s3.enabled }}
extraDeploy:
  - apiVersion: batch/v1
    kind: CronJob
    metadata:
      name: {{ .Name }}-s3-backup # Note: Renamed to avoid conflict if built-in backup is ever enabled
      namespace: {{ .Namespace }}
      labels:
        # Add your standard USD labels here if needed
        unbind/usd-type: {{ .Definition.Type | quote }}
        unbind/usd-version: {{ .Definition.Version | quote }}
        unbind/usd-category: databases
        app.kubernetes.io/instance: {{ .Name }}
        app.kubernetes.io/managed-by: Helm # Indicate Helm management
        {{- range $key, $value := .Parameters.labels }}
        {{ $key }}: {{ $value | quote }}
        {{- end }}
    spec:
      schedule: {{ .Parameters.s3.backupSchedule | default "5 5 * * *" | quote }}
      concurrencyPolicy: Forbid
      jobTemplate:
        spec:
          template:
            spec:
              containers:
              - name: mongodump-s3
                # Use an appropriate mongo image version based on .Parameters.version
                image: {{ if eq (.Parameters.version | default "8.0") "8.0" }}mongo:8.0{{ else if eq .Parameters.version "7.0" }}mongo:7.0{{ else if eq .Parameters.version "6.0" }}mongo:6.0{{ else }}mongo:8.0{{ end }}
                command:
                - /bin/sh
                - -c
                - |
                  # Install AWS CLI
                  apt-get update && apt-get install -y curl unzip
                  ARCH=$(uname -m)
                  if [ "$ARCH" = "x86_64" ]; then
                    ARCH="x86_64"
                  elif [ "$ARCH" = "aarch64" ]; then
                    ARCH="aarch64"
                  else
                    echo "Unsupported architecture: $ARCH"
                    exit 1
                  fi
                  curl "https://awscli.amazonaws.com/awscli-exe-linux-${ARCH}.zip" -o "awscliv2.zip"
                  unzip awscliv2.zip
                  ./aws/install
                  rm -rf aws awscliv2.zip

                  echo "Starting backup..."
                  mongodump --host={{ .Name }}.{{ .Namespace }}.svc.cluster.local \
                            --username=root \
                            --password=$MONGODB_ROOT_PASSWORD \
                            --authenticationDatabase=admin \
                            --out=/backup/$(date +%Y%m%d_%H%M%S)

                  echo "Syncing to S3..."
                  aws s3 sync /backup s3://{{ .Parameters.s3.bucket }}/{{ .Parameters.s3.backupPrefix | default "mongodb" }}/backups/{{ .Name }} \
                    --endpoint-url={{ .Parameters.s3.endpoint }} --checksum-algorithm CRC32

                  echo "Managing retention..."
                  BACKUP_DIRS=$(aws s3 ls s3://{{ .Parameters.s3.bucket }}/{{ .Parameters.s3.backupPrefix | default "mongodb" }}/backups/{{ .Name }}/ \
                    --endpoint-url={{ .Parameters.s3.endpoint }} \
                    | grep -E '[0-9]{8}_[0-9]{6}' \
                    | awk '{print $2}' \
                    | sort)

                  # Count the number of backups
                  BACKUP_COUNT=$(echo "$BACKUP_DIRS" | wc -l)
                  RETENTION={{ .Parameters.s3.backupRetention | default "7" }}

                  # Delete oldest backups if we have more than retention limit
                  if [ "$BACKUP_COUNT" -gt "$RETENTION" ]; then
                    # Calculate how many to delete
                    TO_DELETE=$((BACKUP_COUNT - RETENTION))
                    
                    # Get the oldest backups to delete
                    DIRS_TO_DELETE=$(echo "$BACKUP_DIRS" | head -n "$TO_DELETE")
                    
                    # Delete each old backup
                    echo "$DIRS_TO_DELETE" | while read -r dir; do
                      if [ -n "$dir" ]; then
                        echo "Deleting old backup: $dir"
                        aws s3 rm "s3://{{ .Parameters.s3.bucket }}/{{ .Parameters.s3.backupPrefix | default "mongodb" }}/backups/{{ .Name }}/$dir" \
                          --recursive \
                          --endpoint-url={{ .Parameters.s3.endpoint }}
                      fi
                    done
                    
                    echo "Deleted $TO_DELETE old backups, keeping $RETENTION latest backups."
                  else
                    echo "Only have $BACKUP_COUNT backups, below retention limit of $RETENTION. Nothing to delete."
                  fi
                  echo "Backup complete."
                env:
                # Inject root password from the main auth secret
                - name: MONGODB_ROOT_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      # Use the same secret name as defined in auth.existingSecret
                      name: {{ .Parameters.existingSecretName }}
                      key: mongodb-root-password
                # Inject AWS Credentials from the S3 secret
                - name: AWS_ACCESS_KEY_ID
                  valueFrom:
                    secretKeyRef:
                      name: {{ .Parameters.s3.secretName }}
                      key: {{ .Parameters.s3.accessKey | default "access_key_id" }}
                - name: AWS_SECRET_ACCESS_KEY
                  valueFrom:
                    secretKeyRef:
                      name: {{ .Parameters.s3.secretName }}
                      key: {{ .Parameters.s3.secretKey | default "secret_key" }}
                {{- if .Parameters.s3.region }}
                - name: AWS_DEFAULT_REGION
                  value: {{ .Parameters.s3.region | quote }}
                {{- end }}
                - name: AWS_S3_FORCE_PATH_STYLE
                  value: "true"
                - name: AWS_S3_ENDPOINT_URL
                  value: {{ .Parameters.s3.endpoint | quote }}
                volumeMounts:
                - name: backup-storage
                  mountPath: /backup
              volumes:
              - name: backup-storage
                emptyDir: {}
              restartPolicy: OnFailure
{{- end }}

{{- if .Parameters.restore.enabled }}
  - apiVersion: batch/v1
    kind: Job
    metadata:
      name: {{ .Name }}-s3-restore
      namespace: {{ .Namespace }}
      annotations:
        # Helm Hook annotations
        "helm.sh/hook": post-install,post-upgrade
        "helm.sh/hook-weight": "1" # Run after main resources are likely ready
        "helm.sh/hook-delete-policy": before-hook-creation # Ensure it only runs effectively once
      labels:
        unbind/usd-type: {{ .Definition.Type | quote }}
        unbind/usd-version: {{ .Definition.Version | quote }}
        unbind/usd-category: databases
        app.kubernetes.io/instance: {{ .Name }}
        app.kubernetes.io/managed-by: Helm
        {{- range $key, $value := .Parameters.labels }}
        {{ $key }}: {{ $value | quote }}
        {{- end }}
    spec:
      template:
        spec:
          containers:
          - name: mongorestore-s3
            image: {{ if eq (.Parameters.version | default "8.0") "8.0" }}mongo:8.0{{ else if eq .Parameters.version "7.0" }}mongo:7.0{{ else if eq .Parameters.version "6.0" }}mongo:6.0{{ else }}mongo:8.0{{ end }}
            command:
            - /bin/sh
            - -c
            - |
              # Install AWS CLI
              apt-get update && apt-get install -y curl unzip
              ARCH=$(uname -m)
              if [ "$ARCH" = "x86_64" ]; then
                ARCH="x86_64"
              elif [ "$ARCH" = "aarch64" ]; then
                ARCH="aarch64"
              else
                echo "Unsupported architecture: $ARCH"
                exit 1
              fi
              curl "https://awscli.amazonaws.com/awscli-exe-linux-${ARCH}.zip" -o "awscliv2.zip"
              unzip awscliv2.zip
              ./aws/install
              rm -rf aws awscliv2.zip

              echo "Verifying S3 connection..."
              aws s3 ls s3://{{ .Parameters.restore.bucket }} --endpoint-url={{ .Parameters.restore.endpoint }} --debug
              
              echo "Downloading restore data from S3..."
              aws s3 sync s3://{{ .Parameters.restore.bucket }}/{{ .Parameters.restore.backupPrefix | default "mongodb" }}/backups/{{ .Parameters.restore.cluster }} /restore \
                --endpoint-url={{ .Parameters.restore.endpoint }} --checksum-algorithm CRC32

              RESTORE_DIR=$(ls -t /restore | head -n1)
              if [ -z "$RESTORE_DIR" ]; then
                echo "Error: No backup directory found in /restore"
                exit 1
              fi
              echo "Restoring from directory: $RESTORE_DIR ..."
              mongorestore --host={{ .Name }}.{{ .Namespace }}.svc.cluster.local \
                         --username=root \
                         --password=$MONGODB_ROOT_PASSWORD \
                         --authenticationDatabase=admin \
                         /restore/$RESTORE_DIR
              echo "Restore complete."
            env:
            # Inject root password from the main auth secret
            - name: MONGODB_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  # Use the same secret name as defined in auth.existingSecret
                  name: {{ .Parameters.existingSecretName }}
                  key: mongodb-root-password
            # Inject AWS Credentials from the Restore secret
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: {{ .Parameters.restore.secretName }}
                  key: {{ .Parameters.restore.accessKey | default "access_key_id" }}
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: {{ .Parameters.restore.secretName }}
                  key: {{ .Parameters.restore.secretKey | default "secret_key" }}
            {{- if .Parameters.restore.region }}
            - name: AWS_DEFAULT_REGION
              value: {{ .Parameters.restore.region | quote }}
            {{- end }}
            - name: AWS_S3_FORCE_PATH_STYLE
              value: "true"
            - name: AWS_S3_ENDPOINT_URL
              value: {{ .Parameters.restore.endpoint | quote }}
            volumeMounts:
            - name: restore-storage
              mountPath: /restore
          volumes:
          - name: restore-storage
            emptyDir: {}
          restartPolicy: Never # Important: Change from OnFailure for hooks
{{- end }}