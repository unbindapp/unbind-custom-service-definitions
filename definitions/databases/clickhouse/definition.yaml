apiVersion: clickhouse.altinity.com/v1
kind: ClickHouseInstallation
metadata:
  name: {{ .Name }}
  namespace: {{ .Namespace }}
  labels:
    # Standard USD labels
    unbind/usd-type: {{ .Definition.Type | quote }}
    unbind/usd-version: {{ .Definition.Version | quote }}
    unbind/usd-category: databases
    {{- range $key, $value := .Parameters.labels }}
    {{ $key }}: {{ $value | quote }}
    {{- end }}
spec:
  configuration:
    files:
      config.d/99-logging.xml: |
        <clickhouse>
          <logger>
            <level>warning</level>
            <console>true</console>
          </logger>

          <query_log replace="1">
            <database>system</database>
            <table>query_log</table>
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
            <engine>
              ENGINE = MergeTree
              PARTITION BY event_date
              ORDER BY (event_time)
              TTL event_date + interval 30 day
              SETTINGS ttl_only_drop_parts = 1
            </engine>
          </query_log>

          <!-- Stops unnecessary logging -->
          <metric_log          remove="remove"/>
          <asynchronous_metric_log remove="remove"/>
          <query_thread_log    remove="remove"/>
          <text_log            remove="remove"/>
          <trace_log           remove="remove"/>
          <session_log         remove="remove"/>
          <part_log            remove="remove"/>
        </clickhouse>

      config.d/99-low-resources.xml: |
        <clickhouse>
          <!-- 500 MB mark-cache -->
          <mark_cache_size>524288000</mark_cache_size>

          <profile>
            <default>
              <max_threads>1</max_threads>
              <max_block_size>8192</max_block_size>
              <max_download_threads>1</max_download_threads>
              <input_format_parallel_parsing>0</input_format_parallel_parsing>
              <output_format_parallel_formatting>0</output_format_parallel_formatting>
            </default>
          </profile>
        </clickhouse>
    users:
      default/password:
        valueFrom:
          secretKeyRef:
            name: {{ .Parameters.existingSecretName }}
            key: password
      default/networks/ip: 0.0.0.0/0 
      # Add backup user for clickhouse-backup
      backup/networks/ip: 0.0.0.0/0
      backup/password:
        valueFrom:
          secretKeyRef:
            name: {{ .Parameters.existingSecretName }}
            key: backup-password
    settings:
      default/max_concurrent_queries: 100

    {{- if gt (.Parameters.common.replicas | default 1) 1 }}
    # Auto-configure ZooKeeper when replicas > 1
    zookeeper:
      nodes:
        - host: zookeeper
          port: 2181
    {{- end }}

    clusters:
      - name: {{ .Parameters.clusterName }}
        layout:
          shardsCount: {{ .Parameters.shardsCount | default 1 }}
          replicasCount: {{ .Parameters.common.replicas | default 1 }}

  templates:
    podTemplates:
      - name: clickhouse-pod-template
        metadata:
          labels:
            # Standard USD labels
            unbind/usd-type: {{ .Definition.Type | quote }}
            unbind/usd-version: {{ .Definition.Version | quote }}
            unbind/usd-category: databases
            {{- range $key, $value := .Parameters.labels }}
            {{ $key }}: {{ $value | quote }}
            {{- end }}
        spec:
          containers:
            - name: clickhouse
              image: clickhouse/clickhouse-server:{{ .Parameters.version | default "25.5" }}
              resources:
                requests:
                  cpu: {{ .Parameters.common.resources.requests.cpu | default "100m" }}
                  memory: {{ .Parameters.common.resources.requests.memory | default "128Mi" }}
                limits:
                  cpu: {{ .Parameters.common.resources.limits.cpu | default "500m" }}
                  memory: {{ .Parameters.common.resources.limits.memory | default "256Mi" }}
              {{- if .Parameters.environment }}
              env:
                {{- range $k, $v := .Parameters.environment }}
                - name: {{ $k }}
                  value: {{ $v | quote }}
                {{- end }}
              {{- end }}
              ports:
                - name: http
                  containerPort: 8123
                - name: tcp
                  containerPort: 9000
                - name: interserver
                  containerPort: 9009
              volumeMounts:
                - name: clickhouse-data
                  mountPath: /var/lib/clickhouse

    volumeClaimTemplates:
      - name: clickhouse-data
        metadata:
          labels:
            # Standard USD labels
            unbind/usd-type: {{ .Definition.Type | quote }}
            unbind/usd-version: {{ .Definition.Version | quote }}
            unbind/usd-category: databases
            {{- range $key, $value := .Parameters.labels }}
            {{ $key }}: {{ $value | quote }}
            {{- end }}
        spec:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: {{ .Parameters.common.storage | default "1Gi" }}

    serviceTemplates:
      - name: service-template
        metadata:
          labels:
            # Standard USD labels
            unbind/usd-type: {{ .Definition.Type | quote }}
            unbind/usd-version: {{ .Definition.Version | quote }}
            unbind/usd-category: databases
            {{- range $key, $value := .Parameters.labels }}
            {{ $key }}: {{ $value | quote }}
            {{- end }}
        spec:
          ports:
            - name: http
              port: 8123
              targetPort: 8123
            - name: tcp
              port: 9000
              targetPort: 9000
            - name: interserver
              port: 9009
              targetPort: 9009
          type: {{ if .Parameters.common.exposeExternal }}LoadBalancer{{ else }}ClusterIP{{ end }}

  defaults:
    templates:
      podTemplate: clickhouse-pod-template
      volumeClaimTemplate: clickhouse-data
      serviceTemplate: service-template
{{- if .Parameters.s3.enabled }}
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: "{{ .Name }}-backup"
  namespace: "{{ .Namespace }}"
  labels:
    # Standard USD labels
    unbind/usd-type: {{ .Definition.Type | quote }}
    unbind/usd-version: {{ .Definition.Version | quote }}
    unbind/usd-category: databases
    {{- range $key, $value := .Parameters.labels }}
    {{ $key }}: {{ $value | quote }}
    {{- end }}
spec:
  schedule: "{{ .Parameters.s3.backupSchedule | default "0 2 * * *" }}"
  concurrencyPolicy: "Forbid"
  jobTemplate:
    spec:
      backoffLimit: 1
      completions: 1
      parallelism: 1
      template:
        metadata:
          labels:
            app: "{{ .Name }}-backup"
        spec:
          restartPolicy: Never
          containers:
            - name: clickhouse-backup
              image: altinity/clickhouse-backup:latest
              imagePullPolicy: Always
              env:
                - name: LOG_LEVEL
                  value: "info"
                - name: ALLOW_EMPTY_BACKUPS
                  value: "true"
                - name: BACKUPS_TO_KEEP_REMOTE
                  value: "{{ .Parameters.s3.backupRetention | default "3" }}"
                - name: REMOTE_STORAGE
                  value: "s3"
                - name: S3_ACL
                  value: "private"
                - name: S3_ENDPOINT
                  value: "{{ .Parameters.s3.endpoint }}"
                - name: S3_REGION
                  value: "{{ .Parameters.s3.region }}"
                - name: S3_BUCKET
                  value: "{{ .Parameters.s3.bucket }}"
                - name: S3_PATH
                  value: "{{ .Parameters.s3.backupPrefix | default "backup" }}/{{ .Parameters.clusterName }}"
                {{- if .Parameters.s3.secretName }}
                - name: S3_ACCESS_KEY
                  valueFrom:
                    secretKeyRef:
                      name: {{ .Parameters.s3.secretName }}
                      key: {{ .Parameters.s3.accessKey | default "access_key_id" }}
                - name: S3_SECRET_KEY
                  valueFrom:
                    secretKeyRef:
                      name: {{ .Parameters.s3.secretName }}
                      key: {{ .Parameters.s3.secretKey | default "secret_key" }}
                {{- else }}
                - name: S3_ACCESS_KEY
                  value: "{{ .Parameters.s3.accessKey }}"
                - name: S3_SECRET_KEY
                  value: "{{ .Parameters.s3.secretKey }}"
                {{- end }}
                - name: S3_FORCE_PATH_STYLE
                  value: "true"
                - name: S3_DISABLE_SSL
                  value: "false"
                # ClickHouse connection settings for backup
                - name: CLICKHOUSE_USERNAME
                  value: "backup"
                - name: CLICKHOUSE_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: {{ .Parameters.existingSecretName }}
                      key: backup-password
                - name: CLICKHOUSE_HOST
                  value: "chi-{{ .Name }}-{{ .Parameters.clusterName }}-0-0"
                - name: CLICKHOUSE_PORT
                  value: "9000"
                # Enable incremental backups
                - name: MAKE_INCREMENT_BACKUP
                  value: "{{ .Parameters.s3.incrementalBackups | default "1" }}"
                - name: FULL_BACKUP_WEEKDAY
                  value: "{{ .Parameters.s3.fullBackupWeekday | default "1" }}"
              command:
                - bash
                - -ec
                - |
                  BACKUP_DATE=$(date +%Y-%m-%d-%H-%M-%S)
                  BACKUP_NAME="{{ .Name }}-$BACKUP_DATE"
                  
                  if [[ "" != "$CLICKHOUSE_PASSWORD" ]]; then
                    CLICKHOUSE_PASSWORD="--password=$CLICKHOUSE_PASSWORD"
                  fi
                  
                  # Check if we should make incremental backup
                  if [[ "1" == "$MAKE_INCREMENT_BACKUP" ]]; then
                    LAST_FULL_BACKUP=$(clickhouse-client -q "SELECT name FROM system.backup_list WHERE location='remote' AND name LIKE '%{{ .Name }}%' AND name LIKE '%full%' AND desc NOT LIKE 'broken%' ORDER BY created DESC LIMIT 1 FORMAT TabSeparatedRaw" --host="$CLICKHOUSE_HOST" --port="$CLICKHOUSE_PORT" --user="$CLICKHOUSE_USERNAME" $CLICKHOUSE_PASSWORD)
                    TODAY_FULL_BACKUP=$(clickhouse-client -q "SELECT name FROM system.backup_list WHERE location='remote' AND name LIKE '%{{ .Name }}%' AND name LIKE '%full%' AND desc NOT LIKE 'broken%' AND toDate(created) = today() ORDER BY created DESC LIMIT 1 FORMAT TabSeparatedRaw" --host="$CLICKHOUSE_HOST" --port="$CLICKHOUSE_PORT" --user="$CLICKHOUSE_USERNAME" $CLICKHOUSE_PASSWORD)
                    PREV_BACKUP_NAME=$(clickhouse-client -q "SELECT name FROM system.backup_list WHERE location='remote' AND desc NOT LIKE 'broken%' ORDER BY created DESC LIMIT 1 FORMAT TabSeparatedRaw" --host="$CLICKHOUSE_HOST" --port="$CLICKHOUSE_PORT" --user="$CLICKHOUSE_USERNAME" $CLICKHOUSE_PASSWORD)
                    
                    if [[ ("$FULL_BACKUP_WEEKDAY" == "$(date +%u)" && "" == "$TODAY_FULL_BACKUP") || "" == "$PREV_BACKUP_NAME" || "" == "$LAST_FULL_BACKUP" ]]; then
                      BACKUP_NAME="full-{{ .Name }}-$BACKUP_DATE"
                      DIFF_FROM=""
                    else
                      BACKUP_NAME="increment-{{ .Name }}-$BACKUP_DATE"
                      DIFF_FROM="--diff-from-remote=$PREV_BACKUP_NAME"
                    fi
                  else
                    BACKUP_NAME="full-{{ .Name }}-$BACKUP_DATE"
                    DIFF_FROM=""
                  fi
                  
                  echo "Creating backup: $BACKUP_NAME"
                  clickhouse-backup create "$BACKUP_NAME"
                  
                  echo "Uploading backup: $BACKUP_NAME"
                  clickhouse-backup upload $DIFF_FROM "$BACKUP_NAME"
                  
                  echo "Cleaning up local backup: $BACKUP_NAME"
                  clickhouse-backup delete local "$BACKUP_NAME"
                  
                  echo "BACKUP COMPLETED SUCCESSFULLY"
{{- end }}

{{- if .Parameters.restore.enabled }}
---
apiVersion: batch/v1
kind: Job
metadata:
  name: "{{ .Name }}-restore"
  namespace: "{{ .Namespace }}"
  labels:
    # Standard USD labels
    unbind/usd-type: {{ .Definition.Type | quote }}
    unbind/usd-version: {{ .Definition.Version | quote }}
    unbind/usd-category: databases
    {{- range $key, $value := .Parameters.labels }}
    {{ $key }}: {{ $value | quote }}
    {{- end }}
spec:
  backoffLimit: 0
  template:
    metadata:
      name: "{{ .Name }}-restore"
      labels:
        app: "{{ .Name }}-restore"
    spec:
      restartPolicy: Never
      containers:
        - name: clickhouse-restore
          image: altinity/clickhouse-backup:latest
          imagePullPolicy: Always
          env:
            - name: LOG_LEVEL
              value: "info"
            - name: REMOTE_STORAGE
              value: "s3"
            - name: S3_ACL
              value: "private"
            - name: S3_ENDPOINT
              value: "{{ .Parameters.s3.endpoint }}"
            - name: S3_REGION
              value: "{{ .Parameters.s3.region }}"
            - name: S3_BUCKET
              value: "{{ .Parameters.s3.bucket }}"
            - name: S3_PATH
              value: "{{ .Parameters.s3.backupPrefix | default "backup" }}/{{ .Parameters.clusterName }}"
            {{- if .Parameters.s3.secretName }}
            - name: S3_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: {{ .Parameters.s3.secretName }}
                  key: {{ .Parameters.s3.accessKey | default "access_key_id" }}
            - name: S3_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: {{ .Parameters.s3.secretName }}
                  key: {{ .Parameters.s3.secretKey | default "secret_key" }}
            {{- else }}
            - name: S3_ACCESS_KEY
              value: "{{ .Parameters.s3.accessKey }}"
            - name: S3_SECRET_KEY
              value: "{{ .Parameters.s3.secretKey }}"
            {{- end }}
            - name: S3_FORCE_PATH_STYLE
              value: "true"
            - name: S3_DISABLE_SSL
              value: "false"
            - name: CLICKHOUSE_USERNAME
              value: "backup"
            - name: CLICKHOUSE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: {{ .Parameters.existingSecretName }}
                  key: backup-password
            - name: CLICKHOUSE_HOST
              value: "chi-{{ .Name }}-{{ .Parameters.clusterName }}-0-0"
            - name: CLICKHOUSE_PORT
              value: "9000"
            - name: CHECK_DATABASE
              value: "{{ .Parameters.restore.checkDatabase | default "default" }}"
            - name: CHECK_TABLE
              value: "{{ .Parameters.restore.checkTable | default "" }}"
          command:
            - bash
            - -ec
            - |
              if [[ "" != "$CLICKHOUSE_PASSWORD" ]]; then
                CLICKHOUSE_PASSWORD="--password=$CLICKHOUSE_PASSWORD"
              fi
              
              # Check if cluster is already initialized - if so, skip restore
              DB_EXISTS=$(clickhouse-client -q "SELECT count() FROM system.databases WHERE name = '$CHECK_DATABASE' FORMAT TabSeparatedRaw" --host="$CLICKHOUSE_HOST" --port="$CLICKHOUSE_PORT" --user="$CLICKHOUSE_USERNAME" $CLICKHOUSE_PASSWORD)
              
              # If a specific table is provided, check if it exists
              if [[ "$CHECK_TABLE" != "" && "$DB_EXISTS" == "1" ]]; then
                TABLE_EXISTS=$(clickhouse-client -q "SELECT count() FROM system.tables WHERE database = '$CHECK_DATABASE' AND name = '$CHECK_TABLE' FORMAT TabSeparatedRaw" --host="$CLICKHOUSE_HOST" --port="$CLICKHOUSE_PORT" --user="$CLICKHOUSE_USERNAME" $CLICKHOUSE_PASSWORD)
                
                # If table exists and has data, skip restore
                if [[ "$TABLE_EXISTS" == "1" ]]; then
                  ROW_COUNT=$(clickhouse-client -q "SELECT count() FROM $CHECK_DATABASE.$CHECK_TABLE FORMAT TabSeparatedRaw" --host="$CLICKHOUSE_HOST" --port="$CLICKHOUSE_PORT" --user="$CLICKHOUSE_USERNAME" $CLICKHOUSE_PASSWORD)
                  if [[ "$ROW_COUNT" -gt 0 ]]; then
                    echo "Cluster already initialized with data. Skipping restore."
                    exit 0
                  fi
                fi
              # If we're just checking for database existence
              elif [[ "$DB_EXISTS" == "1" ]]; then
                # Check if any tables exist
                TABLE_COUNT=$(clickhouse-client -q "SELECT count() FROM system.tables WHERE database = '$CHECK_DATABASE' FORMAT TabSeparatedRaw" --host="$CLICKHOUSE_HOST" --port="$CLICKHOUSE_PORT" --user="$CLICKHOUSE_USERNAME" $CLICKHOUSE_PASSWORD)
                if [[ "$TABLE_COUNT" -gt 0 ]]; then
                  echo "Database $CHECK_DATABASE already exists with $TABLE_COUNT tables. Skipping restore."
                  exit 0
                fi
              fi
              
              # Get the latest backup
              LATEST_BACKUP_NAME=$(clickhouse-backup list remote | grep "{{ .Name }}" | head -1 | awk '{print $1}')
              
              if [[ "" == "$LATEST_BACKUP_NAME" ]]; then
                echo "No remote backup found for {{ .Name }}"
                exit 1
              fi
              
              echo "Downloading backup: $LATEST_BACKUP_NAME"
              clickhouse-backup download "$LATEST_BACKUP_NAME"
              
              echo "Restoring backup: $LATEST_BACKUP_NAME"
              clickhouse-backup restore --rm "$LATEST_BACKUP_NAME"
              
              echo "Cleaning up local backup: $LATEST_BACKUP_NAME"
              clickhouse-backup delete local "$LATEST_BACKUP_NAME"
              
              echo "RESTORE COMPLETED SUCCESSFULLY"
{{- end }} 