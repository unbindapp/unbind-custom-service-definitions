apiVersion: clickhouse.altinity.com/v1
kind: ClickHouseInstallation
metadata:
  name: {{ .Name }}
  namespace: {{ .Namespace }}
  labels:
    # Standard USD labels
    unbind/usd-type: {{ .Definition.Type | quote }}
    unbind/usd-version: {{ .Definition.Version | quote }}
    unbind/usd-category: databases
    {{- range $key, $value := .Parameters.labels }}
    {{ $key }}: {{ $value | quote }}
    {{- end }}
spec:
  configuration:
    files:
      config.d/99-logging.xml: |
        <clickhouse>
          <logger>
            <level>warning</level>
            <console>true</console>
          </logger>

          <query_log replace="1">
            <database>system</database>
            <table>query_log</table>
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
            <engine>
              ENGINE = MergeTree
              PARTITION BY event_date
              ORDER BY (event_time)
              TTL event_date + interval 30 day
              SETTINGS ttl_only_drop_parts = 1
            </engine>
          </query_log>

          <!-- Stops unnecessary logging -->
          <metric_log          remove="remove"/>
          <asynchronous_metric_log remove="remove"/>
          <query_thread_log    remove="remove"/>
          <text_log            remove="remove"/>
          <trace_log           remove="remove"/>
          <session_log         remove="remove"/>
          <part_log            remove="remove"/>
        </clickhouse>

      config.d/99-low-resources.xml: |
        <clickhouse>
          <!-- 500 MB mark-cache -->
          <mark_cache_size>524288000</mark_cache_size>

          <profile>
            <default>
              <max_threads>1</max_threads>
              <max_block_size>8192</max_block_size>
              <max_download_threads>1</max_download_threads>
              <input_format_parallel_parsing>0</input_format_parallel_parsing>
              <output_format_parallel_formatting>0</output_format_parallel_formatting>
            </default>
          </profile>
        </clickhouse>
    users:
      default/password:
        valueFrom:
          secretKeyRef:
            name: {{ .Parameters.existingSecretName }}
            key: password
      default/networks/ip: 0.0.0.0/0 
      # Add backup user for clickhouse-backup
      backup/networks/ip: 0.0.0.0/0
      backup/password:
        valueFrom:
          secretKeyRef:
            name: {{ .Parameters.existingSecretName }}
            key: backup-password
    settings:
      default/max_concurrent_queries: 100

    {{- if gt (.Parameters.common.replicas | default 1) 1 }}
    # Auto-configure ZooKeeper when replicas > 1
    zookeeper:
      nodes:
        - host: zookeeper
          port: 2181
    {{- end }}

    clusters:
      - name: {{ .Parameters.clusterName }}
        layout:
          shardsCount: {{ .Parameters.shardsCount | default 1 }}
          replicasCount: {{ .Parameters.common.replicas | default 1 }}

  templates:
    podTemplates:
      - name: clickhouse-pod-template
        metadata:
          labels:
            # Standard USD labels
            unbind/usd-type: {{ .Definition.Type | quote }}
            unbind/usd-version: {{ .Definition.Version | quote }}
            unbind/usd-category: databases
            {{- range $key, $value := .Parameters.labels }}
            {{ $key }}: {{ $value | quote }}
            {{- end }}
        {{- if .Parameters.s3.enabled }}
          annotations:
            prometheus.io/scrape: 'true'
            prometheus.io/port: '8888'
            prometheus.io/path: '/metrics'
            clickhouse.backup/scrape: 'true'
            clickhouse.backup/port: '7171'
            clickhouse.backup/path: '/metrics'
        {{- end }}
        spec:
          containers:
            - name: clickhouse
              image: clickhouse/clickhouse-server:{{ .Parameters.version | default "25.5" }}
              resources:
                requests:
                  cpu: {{ .Parameters.common.resources.requests.cpu | default "100m" }}
                  memory: {{ .Parameters.common.resources.requests.memory | default "128Mi" }}
                limits:
                  cpu: {{ .Parameters.common.resources.limits.cpu | default "500m" }}
                  memory: {{ .Parameters.common.resources.limits.memory | default "256Mi" }}
              {{- if .Parameters.environment }}
              env:
                {{- range $k, $v := .Parameters.environment }}
                - name: {{ $k }}
                  value: {{ $v | quote }}
                {{- end }}
              {{- end }}
              ports:
                - name: http
                  containerPort: 8123
                - name: tcp
                  containerPort: 9000
                - name: interserver
                  containerPort: 9009
              volumeMounts:
                - name: clickhouse-data
                  mountPath: /var/lib/clickhouse
            {{- if .Parameters.s3.enabled }}
            - name: clickhouse-backup
              image: altinity/clickhouse-backup:latest
              imagePullPolicy: Always
              args: ["server"]
              env:
                - name: LOG_LEVEL
                  value: "info"
                - name: ALLOW_EMPTY_BACKUPS
                  value: "true"
                - name: API_LISTEN
                  value: "0.0.0.0:7171"
                - name: API_CREATE_INTEGRATION_TABLES
                  value: "true"
                - name: BACKUPS_TO_KEEP_REMOTE
                  value: "{{ .Parameters.s3.backupRetention | default "3" }}"
                - name: REMOTE_STORAGE
                  value: "s3"
                - name: S3_ACL
                  value: "private"
                - name: S3_ENDPOINT
                  value: "{{ .Parameters.s3.endpoint }}"
                - name: S3_REGION
                  value: "{{ .Parameters.s3.region }}"
                - name: S3_BUCKET
                  value: "{{ .Parameters.s3.bucket }}"
                - name: S3_PATH
                  value: "{{ .Parameters.s3.backupPrefix | default "backup" }}/shard-{shard}"
                {{- if .Parameters.s3.secretName }}
                - name: S3_SECRET_NAME
                  value: "{{ .Parameters.s3.secretName }}"
                {{- else }}
                - name: S3_ACCESS_KEY
                  value: "{{ .Parameters.s3.accessKey }}"
                - name: S3_SECRET_KEY
                  value: "{{ .Parameters.s3.secretKey }}"
                {{- end }}
                - name: S3_FORCE_PATH_STYLE
                  value: "true"
                - name: S3_DISABLE_SSL
                  value: "false"
                # ClickHouse connection settings for backup
                - name: CLICKHOUSE_USERNAME
                  value: "backup"
                - name: CLICKHOUSE_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: {{ .Parameters.existingSecretName }}
                      key: backup-password
                - name: CLICKHOUSE_HOST
                  value: "localhost"
                - name: CLICKHOUSE_PORT
                  value: "9000"
                # Additional clickhouse-backup configuration for proper integration
                - name: CLICKHOUSE_SYNC_REPLICATED_TABLES
                  value: "true"
                - name: CLICKHOUSE_FREEZE_BY_PART
                  value: "false"
                - name: API_CREATE_INTEGRATION_TABLES
                  value: "true"
                - name: API_ALLOW_PARALLEL
                  value: "false"
                - name: BACKUPS_TO_KEEP_LOCAL
                  value: "0"
                - name: UPLOAD_BY_PART
                  value: "true"
                - name: DOWNLOAD_BY_PART
                  value: "true"
              ports:
                - name: backup-rest
                  containerPort: 7171
              volumeMounts:
                - name: clickhouse-data
                  mountPath: /var/lib/clickhouse
            {{- end }}

    volumeClaimTemplates:
      - name: clickhouse-data
        metadata:
          labels:
            # Standard USD labels
            unbind/usd-type: {{ .Definition.Type | quote }}
            unbind/usd-version: {{ .Definition.Version | quote }}
            unbind/usd-category: databases
            {{- range $key, $value := .Parameters.labels }}
            {{ $key }}: {{ $value | quote }}
            {{- end }}
        spec:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: {{ .Parameters.common.storage | default "1Gi" }}

    serviceTemplates:
      - name: service-template
        metadata:
          labels:
            # Standard USD labels
            unbind/usd-type: {{ .Definition.Type | quote }}
            unbind/usd-version: {{ .Definition.Version | quote }}
            unbind/usd-category: databases
            {{- range $key, $value := .Parameters.labels }}
            {{ $key }}: {{ $value | quote }}
            {{- end }}
        spec:
          ports:
            - name: http
              port: 8123
              targetPort: 8123
            - name: tcp
              port: 9000
              targetPort: 9000
            - name: interserver
              port: 9009
              targetPort: 9009
            {{- if .Parameters.s3.enabled }}
            - name: backup-api
              port: 7171
              targetPort: 7171
            {{- end }}
          type: {{ if .Parameters.common.exposeExternal }}LoadBalancer{{ else }}ClusterIP{{ end }}

  defaults:
    templates:
      podTemplate: clickhouse-pod-template
      volumeClaimTemplate: clickhouse-data
      serviceTemplate: service-template
{{- if .Parameters.restore.enabled }}
---
apiVersion: batch/v1
kind: Job
metadata:
  name: "{{ .Name }}-restore"
  namespace: "{{ .Namespace }}"
spec:
  backoffLimit: 0
  template:
    metadata:
      name: "{{ .Name }}-restore"
      labels:
        app: "{{ .Name }}-restore"
    spec:
      restartPolicy: Never
      containers:
        - name: clickhouse-restore
          image: clickhouse/clickhouse-client:{{ .Parameters.version | default "25.5" }}
          imagePullPolicy: IfNotPresent
          env:
            - name: CLICKHOUSE_SCHEMA_RESTORE_SERVICES
              value: "chi-{{ .Name }}-{{ .Parameters.clusterName }}-0-0"
            - name: CLICKHOUSE_DATA_RESTORE_SERVICES
              value: "chi-{{ .Name }}-{{ .Parameters.clusterName }}-0-0"
            - name: CLICKHOUSE_PORT
              value: "9000"
            - name: BACKUP_USER
              value: backup
            - name: BACKUP_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: {{ .Parameters.existingSecretName }}
                  key: backup-password
            - name: CHECK_DATABASE
              value: "default"
            - name: CHECK_TABLE
              value: ""
          command:
            - bash
            - -ec
            - |
              if [[ "" != "$BACKUP_PASSWORD" ]]; then
                BACKUP_PASSWORD="--password=$BACKUP_PASSWORD";
              fi;
              declare -A BACKUP_NAMES;
              CLICKHOUSE_SCHEMA_RESTORE_SERVICES=$(echo $CLICKHOUSE_SCHEMA_RESTORE_SERVICES | tr "," " ");
              CLICKHOUSE_DATA_RESTORE_SERVICES=$(echo $CLICKHOUSE_DATA_RESTORE_SERVICES | tr "," " ");
              
              # Always check if cluster is already initialized - if so, skip restore
              FIRST_SERVER=$(echo $CLICKHOUSE_SCHEMA_RESTORE_SERVICES | cut -d' ' -f1)
              
              # Check if the database exists
              DB_EXISTS=$(clickhouse-client -q "SELECT count() FROM system.databases WHERE name = '$CHECK_DATABASE' FORMAT TabSeparatedRaw" --host="$FIRST_SERVER" --port="$CLICKHOUSE_PORT" --user="$BACKUP_USER" $BACKUP_PASSWORD)
              
              # If a specific table is provided, check if it exists
              if [[ "$CHECK_TABLE" != "" && "$DB_EXISTS" == "1" ]]; then
                TABLE_EXISTS=$(clickhouse-client -q "SELECT count() FROM system.tables WHERE database = '$CHECK_DATABASE' AND name = '$CHECK_TABLE' FORMAT TabSeparatedRaw" --host="$FIRST_SERVER" --port="$CLICKHOUSE_PORT" --user="$BACKUP_USER" $BACKUP_PASSWORD)
                
                # If table exists and has data, skip restore
                if [[ "$TABLE_EXISTS" == "1" ]]; then
                  ROW_COUNT=$(clickhouse-client -q "SELECT count() FROM $CHECK_DATABASE.$CHECK_TABLE FORMAT TabSeparatedRaw" --host="$FIRST_SERVER" --port="$CLICKHOUSE_PORT" --user="$BACKUP_USER" $BACKUP_PASSWORD)
                  if [[ "$ROW_COUNT" -gt 0 ]]; then
                    echo "Cluster already initialized with data. Skipping restore."
                    exit 0
                  fi
                fi
              # If we're just checking for database existence
              elif [[ "$DB_EXISTS" == "1" ]]; then
                # Check if any tables exist
                TABLE_COUNT=$(clickhouse-client -q "SELECT count() FROM system.tables WHERE database = '$CHECK_DATABASE' FORMAT TabSeparatedRaw" --host="$FIRST_SERVER" --port="$CLICKHOUSE_PORT" --user="$BACKUP_USER" $BACKUP_PASSWORD)
                if [[ "$TABLE_COUNT" -gt 0 ]]; then
                  echo "Database $CHECK_DATABASE already exists with $TABLE_COUNT tables. Skipping restore."
                  exit 0
                fi
              fi
              
              # Get the latest backup for each server
              for SERVER in $CLICKHOUSE_SCHEMA_RESTORE_SERVICES; do
                SHARDED_PREFIX=${SERVER%-*}
                LATEST_BACKUP_NAME=$(clickhouse-client -q "SELECT name FROM system.backup_list WHERE location='remote' AND desc NOT LIKE 'broken%' AND name LIKE '%${SHARDED_PREFIX}%' ORDER BY created DESC LIMIT 1 FORMAT TabSeparatedRaw" --host="$SERVER" --port="$CLICKHOUSE_PORT" --user="$BACKUP_USER" $BACKUP_PASSWORD);
                if [[ "" == "$LATEST_BACKUP_NAME" ]]; then
                  echo "Remote backup not found for $SERVER";
                  exit 1;
                fi;
                BACKUP_NAMES[$SERVER]="$LATEST_BACKUP_NAME";
                echo "Using backup: ${BACKUP_NAMES[$SERVER]} for $SERVER"
              done;
              
              # First restore the schema on all replicas
              for SERVER in $CLICKHOUSE_SCHEMA_RESTORE_SERVICES; do
                clickhouse-client -mn --echo -q "INSERT INTO system.backup_actions(command) VALUES('restore_remote --schema --rm ${BACKUP_NAMES[$SERVER]}')" --host="$SERVER" --port="$CLICKHOUSE_PORT" --user="$BACKUP_USER" $BACKUP_PASSWORD;
                
                while [[ "in progress" == $(clickhouse-client -mn -q "SELECT status FROM system.backup_actions WHERE command='restore_remote --schema --rm ${BACKUP_NAMES[$SERVER]}' ORDER BY start DESC LIMIT 1 FORMAT TabSeparatedRaw" --host="$SERVER" --port="$CLICKHOUSE_PORT" --user="$BACKUP_USER" $BACKUP_PASSWORD) ]]; do
                  echo "still in progress ${BACKUP_NAMES[$SERVER]} on $SERVER";
                  sleep 1;
                done;
                
                RESTORE_STATUS=$(clickhouse-client -mn -q "SELECT status FROM system.backup_actions WHERE command='restore_remote --schema --rm ${BACKUP_NAMES[$SERVER]}'  ORDER BY start DESC LIMIT 1 FORMAT TabSeparatedRaw" --host="$SERVER" --port="$CLICKHOUSE_PORT" --user="$BACKUP_USER" $BACKUP_PASSWORD);
                if [[ "success" != "${RESTORE_STATUS}" ]]; then
                  echo "error restore_remote --schema --rm ${BACKUP_NAMES[$SERVER]} on $SERVER";
                  clickhouse-client -mn --echo -q "SELECT start,finish,status,error FROM system.backup_actions WHERE command='restore_remote --schema --rm ${BACKUP_NAMES[$SERVER]}'" --host="$SERVER" --port="$CLICKHOUSE_PORT" --user="$BACKUP_USER" $BACKUP_PASSWORD;
                  exit 1;
                fi;
                
                if [[ "success" == "${RESTORE_STATUS}" ]]; then
                  echo "schema ${BACKUP_NAMES[$SERVER]} on $SERVER RESTORED";
                  clickhouse-client -q "INSERT INTO system.backup_actions(command) VALUES('delete local ${BACKUP_NAMES[$SERVER]}')" --host="$SERVER" --port="$CLICKHOUSE_PORT" --user="$BACKUP_USER" $BACKUP_PASSWORD;
                fi;
              done;
              
              # Then restore data only on the first replica
              for SERVER in $CLICKHOUSE_DATA_RESTORE_SERVICES; do
                clickhouse-client -mn --echo -q "INSERT INTO system.backup_actions(command) VALUES('restore_remote --data ${BACKUP_NAMES[$SERVER]}')" --host="$SERVER" --port="$CLICKHOUSE_PORT" --user="$BACKUP_USER" $BACKUP_PASSWORD;
                
                while [[ "in progress" == $(clickhouse-client -mn -q "SELECT status FROM system.backup_actions WHERE command='restore_remote --data ${BACKUP_NAMES[$SERVER]}' ORDER BY start DESC LIMIT 1 FORMAT TabSeparatedRaw" --host="$SERVER" --port="$CLICKHOUSE_PORT" --user="$BACKUP_USER" $BACKUP_PASSWORD) ]]; do
                  echo "still in progress ${BACKUP_NAMES[$SERVER]} on $SERVER";
                  sleep 1;
                done;
                
                RESTORE_STATUS=$(clickhouse-client -mn -q "SELECT status FROM system.backup_actions WHERE command='restore_remote --data ${BACKUP_NAMES[$SERVER]}'  ORDER BY start DESC LIMIT 1 FORMAT TabSeparatedRaw" --host="$SERVER" --port="$CLICKHOUSE_PORT" --user="$BACKUP_USER" $BACKUP_PASSWORD);
                if [[ "success" != "${RESTORE_STATUS}" ]]; then
                  echo "error restore_remote --data ${BACKUP_NAMES[$SERVER]} on $SERVER";
                  clickhouse-client -mn --echo -q "SELECT start,finish,status,error FROM system.backup_actions WHERE command='restore_remote --data ${BACKUP_NAMES[$SERVER]}'" --host="$SERVER" --port="$CLICKHOUSE_PORT" --user="$BACKUP_USER" $BACKUP_PASSWORD;
                  exit 1;
                fi;
                
                echo "data ${BACKUP_NAMES[$SERVER]} on $SERVER RESTORED";
                if [[ "success" == "${RESTORE_STATUS}" ]]; then
                  clickhouse-client -q "INSERT INTO system.backup_actions(command) VALUES('delete local ${BACKUP_NAMES[$SERVER]}')" --host="$SERVER" --port="$CLICKHOUSE_PORT" --user="$BACKUP_USER" $BACKUP_PASSWORD;
                fi;
              done
              
              echo "RESTORE COMPLETED SUCCESSFULLY"
{{- end }} 